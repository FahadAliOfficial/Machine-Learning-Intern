{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEiEo9kh/dP4sTb6rDwk69"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eBMyCjmE6w4_"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.image as img\n","%matplotlib inline\n","import numpy as np\n","from collections import defaultdict\n","import collections\n","from shutil import copy\n","from shutil import copytree, rmtree\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.regularizers import l2\n","from tensorflow import keras\n","from tensorflow.keras import models\n","import cv2"]},{"cell_type":"code","source":["# Check if GPU is enabled\n","print(tf.__version__)\n","print(tf.test.gpu_device_name())"],"metadata":{"id":"mq2MQjmI6zhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper function to download data and extract\n","def get_data_extract():\n","  if \"food-101\" in os.listdir():\n","    print(\"Dataset already exists\")\n","  else:\n","    print(\"Downloading the data...\")\n","    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n","    print(\"Dataset downloaded!\")\n","    print(\"Extracting data..\")\n","    !tar xzvf food-101.tar.gz\n","    print(\"Extraction done!\")"],"metadata":{"id":"cNfgG1Cu6zfA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download data and extract it to folder\n","\n","get_data_extract()"],"metadata":{"id":"uf_pDNyc6zcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Check the extracted dataset folder\n","!ls food-101/"],"metadata":{"id":"GaB0SGcC6zao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir('food-101/images')"],"metadata":{"id":"AnHwTy4T6zYb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir('food-101/meta')"],"metadata":{"id":"b-ybR7aL6zWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","!head food-101/meta/train.txt"],"metadata":{"id":"Senv5G8m6zUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head food-101/meta/classes.txt"],"metadata":{"id":"Tlkapp0X6zSA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize the data, showing one image per class from 101 classes\n","rows = 17\n","cols = 6\n","fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n","fig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n","data_dir = \"food-101/images/\"\n","foods_sorted = sorted(os.listdir(data_dir))\n","food_id = 0\n","for i in range(rows):\n","  for j in range(cols):\n","    try:\n","      food_selected = foods_sorted[food_id]\n","      food_id += 1\n","    except:\n","      break\n","    if food_selected == '.DS_Store':\n","        continue\n","    food_selected_images = os.listdir(os.path.join(data_dir,food_selected)) # returns the list of all files present in each food category\n","    food_selected_random = np.random.choice(food_selected_images) # picks one food item from the list as choice, takes a list and returns one random item\n","    img = plt.imread(os.path.join(data_dir,food_selected, food_selected_random))\n","    ax[i][j].imshow(img)\n","    ax[i][j].set_title(food_selected, pad = 10)\n","\n","plt.setp(ax, xticks=[],yticks=[])\n","plt.tight_layout()\n","# https://matplotlib.org/users/tight_layout_guide.html"],"metadata":{"id":"8u-LGAgH6zP4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper method to split dataset into train and test folders\n","def prepare_data(filepath, src,dest):\n","  classes_images = defaultdict(list)\n","  with open(filepath, 'r') as txt:\n","      paths = [read.strip() for read in txt.readlines()]\n","      for p in paths:\n","        food = p.split('/')\n","        classes_images[food[0]].append(food[1] + '.jpg')\n","\n","  for food in classes_images.keys():\n","    print(\"\\nCopying images into \",food)\n","    if not os.path.exists(os.path.join(dest,food)):\n","      os.makedirs(os.path.join(dest,food))\n","    for i in classes_images[food]:\n","      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n","  print(\"Copying Done!\")"],"metadata":{"id":"bGhJe6io6zNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n","print(\"Creating train data...\")\n","prepare_data('/food-101/food-101/meta/train.txt', '/food-101/food-101/images', 'train')"],"metadata":{"id":"VJr_zyJ36zHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n","print(\"Creating test data...\")\n","prepare_data('food-101/food-101/meta/test.txt', 'food-101/food-101/images', 'test')"],"metadata":{"id":"BPCKDHjd7UIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Check how many files are in the train folder\n","print(\"Total number of samples in train folder\")\n","!find train -type d -or -type f -printf '.' | wc -c"],"metadata":{"id":"Zk9gbmoG7UD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Check how many files are in the test folder\n","print(\"Total number of samples in test folder\")\n","!find test -type d -or -type f -printf '.' | wc -c"],"metadata":{"id":"90umvoQH7UB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","os.chdir('/')"],"metadata":{"id":"fgdd2axq7T_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List of all 101 types of foods(sorted alphabetically)\n","del foods_sorted[0] # remove .DS_Store from the list"],"metadata":{"id":"3N0U9u007T9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["foods_sorted"],"metadata":{"id":"rTWIzQ047T5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper method to create train_mini and test_mini data samples\n","def dataset_mini(food_list, src, dest):\n","  if os.path.exists(dest):\n","    rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\n","  os.makedirs(dest)\n","  for food_item in food_list :\n","    print(\"Copying images into\",food_item)\n","    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))\n",""],"metadata":{"id":"ovxzxIG27nXw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# picking 3 food items and generating separate data folders for the same\n","food_list = ['apple_pie','pizza','omelette']\n","src_train = 'train'\n","dest_train = 'train_mini/'\n","src_test = 'test'\n","dest_test = 'test_mini/'"],"metadata":{"id":"agihwT3k7nVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Creating train data folder with new classes\")\n","dataset_mini(food_list, src_train, dest_train)"],"metadata":{"id":"ZeQBfvp_7nTQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Total number of samples in test folder\")\n","!find /kaggle/working/test_mini -type d -or -type f -printf '.' | wc -c"],"metadata":{"id":"anGpEgVZ7sJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Creating test data folder with new classes\")\n","dataset_mini(food_list, src_test, dest_test)"],"metadata":{"id":"B-PaAxjv7sHh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Total number of samples in test folder\")\n","!find /kaggle/working/test_mini -type d -or -type f -printf '.' | wc -c"],"metadata":{"id":"N7qXv9247sFK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","K.clear_session()\n","n_classes = 3\n","img_width, img_height = 224, 224\n","train_data_dir = 'train_mini'\n","validation_data_dir = 'test_mini'\n","nb_train_samples = 2250 #75750\n","nb_validation_samples = 750 #25250\n","batch_size = 16\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","\n","resnet50 = ResNet50(weights='imagenet', include_top=False)\n","x = resnet50.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(128,activation='relu')(x)\n","x = Dropout(0.2)(x)\n","\n","predictions = Dense(3,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n","\n","model = Model(inputs=resnet50.input, outputs=predictions)\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n","checkpointer = ModelCheckpoint(filepath='best_model_3class.hdf5', verbose=1, save_best_only=True)\n","csv_logger = CSVLogger('history_3class.log')\n","\n","history = model.fit_generator(train_generator,\n","                    steps_per_epoch = nb_train_samples // batch_size,\n","                    validation_data=validation_generator,\n","                    validation_steps=nb_validation_samples // batch_size,\n","                    epochs=30,\n","                    verbose=1,\n","                    callbacks=[csv_logger, checkpointer])\n","\n","model.save('model_trained_3class.hdf5')"],"metadata":{"id":"pEPypPtd7sCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_map_3 = train_generator.class_indices\n","class_map_3"],"metadata":{"id":"Rsw1JrDy76Ss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_accuracy(history,title):\n","    plt.title(title)\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n","    plt.show()\n","def plot_loss(history,title):\n","    plt.title(title)\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train_loss', 'validation_loss'], loc='best')\n","    plt.show()"],"metadata":{"id":"B-7bxpIz76QZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_accuracy(history,'FOOD101-ResNet50')\n","plot_loss(history,'FOOD101-ResNet50')"],"metadata":{"id":"GxmWfguT79Ht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Loading the best saved model to make predictions\n","K.clear_session()\n","model_best = load_model('/kaggle/working/best_model_3class.hdf5',compile = False)"],"metadata":{"id":"2024XjVA79FT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_class(model, images, show = True):\n","  for img in images:\n","    img = image.load_img(img, target_size=(224, 224))\n","    img = image.img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img /= 255.\n","\n","    pred = model.predict(img)\n","    index = np.argmax(pred)\n","    food_list.sort()\n","    pred_value = food_list[index]\n","    if show:\n","        plt.imshow(img[0])\n","        plt.axis('off')\n","        plt.title(pred_value)\n","        plt.show()"],"metadata":{"id":"-msuAZTr79C8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make a list of downloaded images and test the trained model\n","images = []\n","images.append('applepie.jpg')\n","images.append('pizza.jpg')\n","images.append('omelette.jpg')\n","predict_class(model_best, images, True)"],"metadata":{"id":"A2utSSzO76OC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Helper function to select n random food classes\n","def pick_n_random_classes(n):\n","  food_list = []\n","  random_food_indices = random.sample(range(len(foods_sorted)),n) # We are picking n random food classes\n","  for i in random_food_indices:\n","    food_list.append(foods_sorted[i])\n","  food_list.sort()\n","  return food_list"],"metadata":{"id":"SYkohLZO8Vbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lets try with more classes than just 3. Also, this time lets randomly pick the food classes\n","n = 11\n","food_list = pick_n_random_classes(n)\n","food_list = ['apple_pie', 'beef_carpaccio', 'bibimbap', 'cup_cakes', 'foie_gras', 'french_fries', 'garlic_bread', 'pizza', 'spring_rolls', 'spaghetti_carbonara', 'strawberry_shortcake']\n","print(\"These are the randomly picked food classes we will be training the model on...\\n\", food_list)"],"metadata":{"id":"8QK0cLp-8VZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the new data subset of n classes\n","print(\"Creating training data folder with new classes...\")\n","dataset_mini(food_list, src_train, dest_train)"],"metadata":{"id":"dw6_QiaA8VXg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Total number of samples in train folder\")\n","!find train_mini/ -type d -or -type f -printf '.' | wc -c"],"metadata":{"id":"kkie4u5C8a5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Creating test data folder with new classes\")\n","dataset_mini(food_list, src_test, dest_test)"],"metadata":{"id":"Mr0r_Y3R8a2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Total number of samples in test folder\")\n","!find test_mini/ -type d -or -type f -printf '.' | wc -c"],"metadata":{"id":"uFho3p2K8a0T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's use a pretrained Inceptionv3 model on subset of data with 11 food classes\n","K.clear_session()\n","\n","n_classes = n\n","img_width, img_height = 224, 224\n","train_data_dir = 'train_mini'\n","validation_data_dir = 'test_mini'\n","nb_train_samples = 8250 #75750\n","nb_validation_samples = 2750 #25250\n","batch_size = 16\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","\n","resnet50 = ResNet50(weights='imagenet', include_top=False)\n","x = resnet50.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(128,activation='relu')(x)\n","x = Dropout(0.2)(x)\n","\n","predictions = Dense(n,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n","\n","model = Model(inputs=resnet50.input, outputs=predictions)\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n","checkpointer = ModelCheckpoint(filepath='best_model_11class.hdf5', verbose=1, save_best_only=True)\n","csv_logger = CSVLogger('history_11class.log')\n","\n","history_11class = model.fit_generator(train_generator,\n","                    steps_per_epoch = nb_train_samples // batch_size,\n","                    validation_data=validation_generator,\n","                    validation_steps=nb_validation_samples // batch_size,\n","                    epochs=30,\n","                    verbose=1,\n","                    callbacks=[csv_logger, checkpointer])\n","\n","model.save('model_trained_11class.hdf5')"],"metadata":{"id":"i85LKRpd8VVJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_map_11 = train_generator.class_indices\n","class_map_11"],"metadata":{"id":"Kv43YA2_8VSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_accuracy(history_11class,'FOOD101-ResNet50')\n","plot_loss(history_11class,'FOOD101-ResNet50')"],"metadata":{"id":"thlrHets8VQc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Loading the best saved model to make predictions\n","K.clear_session()\n","model_best = load_model('/kaggle/working/best_model_11class.hdf5',compile = False)"],"metadata":{"id":"vkILnHtM76Lw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make a list of downloaded images and test the trained model\n","images = []\n","images.append('cupcakes.jpg')\n","# images.append('pizza.jpg')\n","images.append('springrolls.jpg')\n","images.append('garlicbread.jpg')\n","predict_class(model_best, images, True)"],"metadata":{"id":"KVAsBMjN8kVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","os.chdir(\"AbdulQadeer/Dataset/\")"],"metadata":{"id":"Xss4GXtR8kTZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"],"metadata":{"id":"GE_nhDWU8kRJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gxclsaBr6y6g"},"execution_count":null,"outputs":[]}]}